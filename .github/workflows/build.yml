name: Build and Deploy Packages

on:
  push:
    branches: [master]
    paths:
      - "src/**"
      - "!src/**/.nvchecker.toml"
  pull_request:
    paths:
      - "src/**"
      - "!src/**/.nvchecker.toml"
  workflow_dispatch:
    inputs:
      package:
        description: "Package name to build (leave empty for all changed)"
        required: false
        type: string

env:
  REPO_NAME: slinet

jobs:
  detect-changes:
    runs-on: ubuntu-latest
    outputs:
      packages: ${{ steps.changes.outputs.packages }}
      has_packages: ${{ steps.changes.outputs.has_packages }}
    steps:
      - uses: actions/checkout@v6
        with:
          fetch-depth: 0

      - name: Detect changed packages
        id: changes
        run: |
          if [ -n "${{ github.event.inputs.package }}" ]; then
            # Manual trigger with specific package
            PACKAGES='["${{ github.event.inputs.package }}"]'
          elif [ "${{ github.event_name }}" = "push" ]; then
            # Get changed packages from commit (exclude .nvchecker.toml changes)
            CHANGED=$(git diff --name-only ${{ github.event.before }} ${{ github.sha }} 2>/dev/null | \
              grep '^src/' | grep -v '\.nvchecker\.toml$' | cut -d'/' -f2 | sort -u | jq -R -s -c 'split("\n")[:-1] | map(select(length > 0))')
            PACKAGES="${CHANGED:-[]}"
          else
            # For PRs, compare with base branch (exclude .nvchecker.toml changes)
            CHANGED=$(git diff --name-only origin/${{ github.base_ref }}...HEAD 2>/dev/null | \
              grep '^src/' | grep -v '\.nvchecker\.toml$' | cut -d'/' -f2 | sort -u | jq -R -s -c 'split("\n")[:-1] | map(select(length > 0))')
            PACKAGES="${CHANGED:-[]}"
          fi

          echo "packages=$PACKAGES" >> $GITHUB_OUTPUT
          if [ "$PACKAGES" = "[]" ] || [ -z "$PACKAGES" ]; then
            echo "has_packages=false" >> $GITHUB_OUTPUT
          else
            echo "has_packages=true" >> $GITHUB_OUTPUT
          fi
          echo "Detected packages: $PACKAGES"

  build:
    needs: detect-changes
    if: needs.detect-changes.outputs.has_packages == 'true'
    runs-on: ubuntu-latest
    strategy:
      matrix:
        package: ${{ fromJson(needs.detect-changes.outputs.packages) }}
      fail-fast: false

    steps:
      - uses: actions/checkout@v6

      - name: Build package with archpkg-build
        uses: Slinet6056/archpkg-build@v1
        with:
          package_name: ${{ matrix.package }}
          gpg_private_key: ${{ secrets.GPG_PRIVATE_KEY }}
          gpg_passphrase: ${{ secrets.GPG_PASSPHRASE }}
          pkgs_path: src

      - name: Upload build artifacts
        uses: actions/upload-artifact@v6
        with:
          name: pkg-${{ matrix.package }}
          path: |
            src/${{ matrix.package }}/*.pkg.tar.zst
            src/${{ matrix.package }}/*.pkg.tar.zst.sig
          retention-days: 1
          if-no-files-found: error

  deploy:
    needs: [detect-changes, build]
    if: github.event_name != 'pull_request' && needs.detect-changes.outputs.has_packages == 'true'
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v6

      - name: Download all artifacts
        uses: actions/download-artifact@v7
        with:
          path: packages
          pattern: pkg-*
          merge-multiple: true

      - name: Setup rclone for R2
        run: |
          curl -O https://downloads.rclone.org/rclone-current-linux-amd64.deb
          sudo dpkg -i rclone-current-linux-amd64.deb

          mkdir -p ~/.config/rclone
          cat > ~/.config/rclone/rclone.conf << EOF
          [r2]
          type = s3
          provider = Cloudflare
          access_key_id = ${{ secrets.CLOUDFLARE_ACCESS_KEY_ID }}
          secret_access_key = ${{ secrets.CLOUDFLARE_SECRET_ACCESS_KEY }}
          endpoint = https://${{ secrets.CLOUDFLARE_ACCOUNT_ID }}.r2.cloudflarestorage.com
          acl = private
          no_check_bucket = true
          EOF

      - name: Download existing database
        run: |
          mkdir -p repo
          # Try to fetch existing database files
          rclone copy r2:arch-repo/${{ env.REPO_NAME }}.db.tar.gz repo/ 2>/dev/null || true
          rclone copy r2:arch-repo/${{ env.REPO_NAME }}.files.tar.gz repo/ 2>/dev/null || true

          # Create db symlinks if files exist
          if [ -f repo/${{ env.REPO_NAME }}.db.tar.gz ]; then
            cp repo/${{ env.REPO_NAME }}.db.tar.gz repo/${{ env.REPO_NAME }}.db
          fi
          if [ -f repo/${{ env.REPO_NAME }}.files.tar.gz ]; then
            cp repo/${{ env.REPO_NAME }}.files.tar.gz repo/${{ env.REPO_NAME }}.files
          fi

      - name: Update repository database
        run: |
          # Move built packages to repo directory
          find packages -name "*.pkg.tar.zst" -exec mv {} repo/ \;
          find packages -name "*.pkg.tar.zst.sig" -exec mv {} repo/ \; 2>/dev/null || true

          # Create GPG passphrase file if GPG is enabled
          if [ "${{ vars.GPG_ENABLED }}" = "true" ]; then
            echo "${{ secrets.GPG_PASSPHRASE }}" > repo/.gpg-passphrase
            chmod 600 repo/.gpg-passphrase
          fi

          # Use Arch Linux container to run repo-add
          docker run --rm \
            -v "$(pwd)/repo:/repo" \
            -v "$(pwd)/scripts:/scripts" \
            -w /repo \
            -e GPG_PRIVATE_KEY="${{ secrets.GPG_PRIVATE_KEY }}" \
            -e GPG_ENABLED="${{ vars.GPG_ENABLED }}" \
            -e REPO_NAME="${{ env.REPO_NAME }}" \
            archlinux:latest \
            bash -c "
              pacman -Sy --noconfirm pacman-contrib gnupg

              # Setup GPG for signing
              source /scripts/setup-gpg.sh

              # Update repository database
              bash /scripts/update-repo-db.sh ${{ env.REPO_NAME }}
            "

          # Clean up passphrase file from host
          rm -f repo/.gpg-passphrase

      - name: Upload to Cloudflare R2
        run: |
          cd repo

          # Upload package files
          for file in *.pkg.tar.zst *.pkg.tar.zst.sig; do
            if [ -f "$file" ]; then
              rclone copyto "$file" "r2:arch-repo/$file"
              echo "Uploaded: $file"
            fi
          done

          # Upload database files
          rclone copyto ${{ env.REPO_NAME }}.db.tar.gz r2:arch-repo/${{ env.REPO_NAME }}.db.tar.gz
          rclone copyto ${{ env.REPO_NAME }}.files.tar.gz r2:arch-repo/${{ env.REPO_NAME }}.files.tar.gz
          rclone copyto ${{ env.REPO_NAME }}.db.tar.gz r2:arch-repo/${{ env.REPO_NAME }}.db
          rclone copyto ${{ env.REPO_NAME }}.files.tar.gz r2:arch-repo/${{ env.REPO_NAME }}.files

          # Upload database signature files if they exist
          if [ -f "${{ env.REPO_NAME }}.db.tar.gz.sig" ]; then
            rclone copyto ${{ env.REPO_NAME }}.db.tar.gz.sig r2:arch-repo/${{ env.REPO_NAME }}.db.tar.gz.sig
            rclone copyto ${{ env.REPO_NAME }}.db.tar.gz.sig r2:arch-repo/${{ env.REPO_NAME }}.db.sig
            echo "Uploaded database signatures"
          fi
          if [ -f "${{ env.REPO_NAME }}.files.tar.gz.sig" ]; then
            rclone copyto ${{ env.REPO_NAME }}.files.tar.gz.sig r2:arch-repo/${{ env.REPO_NAME }}.files.tar.gz.sig
            rclone copyto ${{ env.REPO_NAME }}.files.tar.gz.sig r2:arch-repo/${{ env.REPO_NAME }}.files.sig
            echo "Uploaded files database signatures"
          fi

          echo "Repository updated successfully!"

      - name: Cleanup old package versions
        run: |
          bash scripts/cleanup-old-packages.sh 2 r2:arch-repo
